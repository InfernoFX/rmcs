{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "93c4d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "65a375d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1389 entries, 1 to 42\n",
      "Data columns (total 27 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   date          1389 non-null   object \n",
      " 1   time          1389 non-null   object \n",
      " 2   comp          1389 non-null   object \n",
      " 3   round         1389 non-null   object \n",
      " 4   day           1389 non-null   object \n",
      " 5   venue         1389 non-null   object \n",
      " 6   result        1389 non-null   object \n",
      " 7   gf            1389 non-null   float64\n",
      " 8   ga            1389 non-null   float64\n",
      " 9   opponent      1389 non-null   object \n",
      " 10  xg            1389 non-null   float64\n",
      " 11  xga           1389 non-null   float64\n",
      " 12  poss          1389 non-null   float64\n",
      " 13  attendance    693 non-null    float64\n",
      " 14  captain       1389 non-null   object \n",
      " 15  formation     1389 non-null   object \n",
      " 16  referee       1389 non-null   object \n",
      " 17  match report  1389 non-null   object \n",
      " 18  notes         0 non-null      float64\n",
      " 19  sh            1389 non-null   float64\n",
      " 20  sot           1389 non-null   float64\n",
      " 21  dist          1388 non-null   float64\n",
      " 22  fk            1389 non-null   float64\n",
      " 23  pk            1389 non-null   float64\n",
      " 24  pkatt         1389 non-null   float64\n",
      " 25  season        1389 non-null   int64  \n",
      " 26  team          1389 non-null   object \n",
      "dtypes: float64(13), int64(1), object(13)\n",
      "memory usage: 303.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>comp</th>\n",
       "      <th>round</th>\n",
       "      <th>day</th>\n",
       "      <th>venue</th>\n",
       "      <th>result</th>\n",
       "      <th>gf</th>\n",
       "      <th>ga</th>\n",
       "      <th>opponent</th>\n",
       "      <th>...</th>\n",
       "      <th>match report</th>\n",
       "      <th>notes</th>\n",
       "      <th>sh</th>\n",
       "      <th>sot</th>\n",
       "      <th>dist</th>\n",
       "      <th>fk</th>\n",
       "      <th>pk</th>\n",
       "      <th>pkatt</th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>16:30</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Away</td>\n",
       "      <td>L</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>...</td>\n",
       "      <td>Match Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-21</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Norwich City</td>\n",
       "      <td>...</td>\n",
       "      <td>Match Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-28</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>...</td>\n",
       "      <td>Match Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Away</td>\n",
       "      <td>W</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Leicester City</td>\n",
       "      <td>...</td>\n",
       "      <td>Match Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>Matchweek 5</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Home</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>...</td>\n",
       "      <td>Match Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>Manchester City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   time            comp        round  day venue result   gf   ga  \\\n",
       "1  2021-08-15  16:30  Premier League  Matchweek 1  Sun  Away      L  0.0  1.0   \n",
       "2  2021-08-21  15:00  Premier League  Matchweek 2  Sat  Home      W  5.0  0.0   \n",
       "3  2021-08-28  12:30  Premier League  Matchweek 3  Sat  Home      W  5.0  0.0   \n",
       "4  2021-09-11  15:00  Premier League  Matchweek 4  Sat  Away      W  1.0  0.0   \n",
       "6  2021-09-18  15:00  Premier League  Matchweek 5  Sat  Home      D  0.0  0.0   \n",
       "\n",
       "         opponent  ...  match report  notes    sh   sot  dist   fk   pk pkatt  \\\n",
       "1       Tottenham  ...  Match Report    NaN  18.0   4.0  16.9  1.0  0.0   0.0   \n",
       "2    Norwich City  ...  Match Report    NaN  16.0   4.0  17.3  1.0  0.0   0.0   \n",
       "3         Arsenal  ...  Match Report    NaN  25.0  10.0  14.3  0.0  0.0   0.0   \n",
       "4  Leicester City  ...  Match Report    NaN  25.0   8.0  14.0  0.0  0.0   0.0   \n",
       "6     Southampton  ...  Match Report    NaN  16.0   1.0  15.7  1.0  0.0   0.0   \n",
       "\n",
       "   season             team  \n",
       "1    2022  Manchester City  \n",
       "2    2022  Manchester City  \n",
       "3    2022  Manchester City  \n",
       "4    2022  Manchester City  \n",
       "6    2022  Manchester City  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"C:/Users/62822/RMCS Data/matches.csv\", index_col = 0)\n",
    "\n",
    "dataset.info()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f3e43",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6467aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# away = 1, home = 0\n",
    "\n",
    "dataset['venue'] = dataset.venue.apply(lambda x: 1 if x=='Away' else 0)\n",
    "dataset['result'] = dataset.result.apply(lambda x: 1 if x=='W' else 0  if x == 'D' else 2)\n",
    "\n",
    "dataset = dataset.drop(columns = ['time', 'comp', 'round', 'notes', 'captain', 'referee', 'match report', 'season', 'date', 'day', 'formation', 'opponent'])\n",
    "\n",
    "dataset['dist'] = dataset['dist'].fillna(dataset['dist'].mean())\n",
    "dataset['attendance'] = dataset['attendance'].fillna(dataset['attendance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cd2a7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "dataset = pd.get_dummies(dataset, columns = ['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3c49de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced sample\n",
    "datasetSample0 = dataset[dataset[\"result\"]==0].sample(300)\n",
    "datasetSample0\n",
    "datasetSample1 = dataset[dataset[\"result\"]==1].sample(300)\n",
    "datasetSample1\n",
    "datasetSample2 = dataset[dataset[\"result\"]==2].sample(300)\n",
    "datasetSample2\n",
    "dataset = pd.concat([datasetSample1, datasetSample0, datasetSample2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "602cc243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "1    300\n",
       "0    300\n",
       "2    300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a1fa8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['result'])\n",
    "y = dataset.result\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Test size = 0.3, Train size = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c0cfd",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "82aec67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8857142857142857\n",
      "0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "from xgboost import plot_tree\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "Classifier = XGBClassifier(objective='multi:softmax', \n",
    "                            num_class=3,  \n",
    "                            max_depth = 3,\n",
    "                            learning_rate = 0.1,\n",
    "                            subsample = 0.05,\n",
    "                            colsample_bytree = 0.4,\n",
    "                            seed=42)\n",
    "Classifier.fit(X_train, y_train)\n",
    "# plot_tree(Classifier, rankdir='LR')\n",
    "# plt.show()\n",
    "\n",
    "print(Classifier.score(X_train, y_train))\n",
    "print(Classifier.score(X_test, y_test))\n",
    "\n",
    "prediction = Classifier.predict(X_test)\n",
    "predictionTrain = Classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "18ca4cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.44444444444444\n",
      "88.57142857142857\n",
      "[70.27027027 97.59036145 90.78947368]\n",
      "[74.6031746  94.47004608 94.64285714]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, prediction)*100)\n",
    "print(accuracy_score(y_train, predictionTrain)*100)\n",
    "\n",
    "print(recall_score(y_test, prediction, average=None)*100)\n",
    "print(recall_score(y_train, predictionTrain, average=None)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d4b1d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.70      0.80       111\n",
      "           2       0.87      0.98      0.92        83\n",
      "           0       0.75      0.91      0.82        76\n",
      "\n",
      "    accuracy                           0.84       270\n",
      "   macro avg       0.85      0.86      0.85       270\n",
      "weighted avg       0.86      0.84      0.84       270\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.75      0.81       189\n",
      "           2       0.90      0.94      0.92       217\n",
      "           0       0.87      0.95      0.91       224\n",
      "\n",
      "    accuracy                           0.89       630\n",
      "   macro avg       0.89      0.88      0.88       630\n",
      "weighted avg       0.89      0.89      0.88       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "target_names = ['1', '2', '0']\n",
    "\n",
    "print(classification_report(y_test, prediction, target_names=target_names))\n",
    "print(classification_report(y_train, predictionTrain, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03227c05",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1ca04658",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['result'])\n",
    "y = dataset.result\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Test size = 0.3, Train size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c2cf9828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# parameters = [{'kernel':('linear', 'rbf'), 'C':[1, 10], 'random_state':[26, 42], 'decision_function_shape':('ovo')}]\n",
    "# base_estimator = SVC(random_state=0)\n",
    "# svm = GridSearchCV(base, parameters, cv = 10, scoring='accuracy')\n",
    "\n",
    "svm = SVC(random_state=42, kernel = 'rbf',  cache_size = 500, decision_function_shape = 'ovo', gamma = 'scale', C = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d31efde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "14c5a249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36666666666666664\n",
      "0.25925925925925924\n"
     ]
    }
   ],
   "source": [
    "print(svm.score(X_train, y_train))\n",
    "print(svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4899fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)\n",
    "predictionTrain = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "29a64059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.925925925925924\n",
      "36.666666666666664\n",
      "[ 0.         67.46987952 18.42105263]\n",
      "[ 0.         67.28110599 37.94642857]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(accuracy_score(y_test, prediction)*100)\n",
    "print(accuracy_score(y_train, predictionTrain)*100)\n",
    "\n",
    "print(recall_score(y_test, prediction, average=None)*100)\n",
    "print(recall_score(y_train, predictionTrain, average=None)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "43d3e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       111\n",
      "           2       0.30      0.67      0.42        83\n",
      "           0       0.16      0.18      0.17        76\n",
      "\n",
      "    accuracy                           0.26       270\n",
      "   macro avg       0.16      0.29      0.20       270\n",
      "weighted avg       0.14      0.26      0.18       270\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.35      0.67      0.46       217\n",
      "           0       0.39      0.38      0.38       224\n",
      "\n",
      "    accuracy                           0.37       630\n",
      "   macro avg       0.25      0.35      0.28       630\n",
      "weighted avg       0.26      0.37      0.30       630\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62822\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\62822\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\62822\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\62822\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\62822\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\62822\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "target_names = ['1', '2', '0']\n",
    "\n",
    "print(classification_report(y_test, prediction, target_names=target_names))\n",
    "print(classification_report(y_train, predictionTrain, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1327053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156051b",
   "metadata": {},
   "source": [
    "# Ensemble (Using Logistic Regression as the meta model/second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0d8c3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['result'])\n",
    "y = dataset.result\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Test size = 0.3, Train size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d95e94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [\n",
    "    ('xgboost', XGBClassifier(objective='multi:softmax', \n",
    "                            num_class=3,  \n",
    "                            max_depth = 3,\n",
    "                            learning_rate = 0.1,\n",
    "                            subsample = 0.05,\n",
    "                            colsample_bytree = 0.4,\n",
    "                            seed=42)),\n",
    "    ('svm', SVC(random_state=42, kernel = 'rbf', cache_size = 500, decision_function_shape = 'ovo', gamma = 'scale', C = 3))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "20354fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "eab758e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "acafc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n",
      "0.8703703703703703\n"
     ]
    }
   ],
   "source": [
    "print(ensemble.score(X_train, y_train))\n",
    "print(ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a667b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = ensemble.predict(X_test)\n",
    "predictionTrain = ensemble.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6a39c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.03703703703704\n",
      "91.11111111111111\n",
      "[78.37837838 93.97590361 92.10526316]\n",
      "[83.06878307 94.93087558 94.19642857]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(accuracy_score(y_test, prediction)*100)\n",
    "print(accuracy_score(y_train, predictionTrain)*100)\n",
    "\n",
    "print(recall_score(y_test, prediction, average=None)*100)\n",
    "print(recall_score(y_train, predictionTrain, average=None)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a65ac2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.78      0.84       111\n",
      "           2       0.90      0.94      0.92        83\n",
      "           0       0.80      0.92      0.86        76\n",
      "\n",
      "    accuracy                           0.87       270\n",
      "   macro avg       0.87      0.88      0.87       270\n",
      "weighted avg       0.87      0.87      0.87       270\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.83      0.87       189\n",
      "           2       0.94      0.95      0.94       217\n",
      "           0       0.89      0.94      0.92       224\n",
      "\n",
      "    accuracy                           0.91       630\n",
      "   macro avg       0.91      0.91      0.91       630\n",
      "weighted avg       0.91      0.91      0.91       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "target_names = ['1', '2', '0']\n",
    "\n",
    "print(classification_report(y_test, prediction, target_names=target_names))\n",
    "print(classification_report(y_train, predictionTrain, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
